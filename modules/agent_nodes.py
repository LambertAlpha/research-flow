#!/usr/bin/env python3
"""
LangGraph Multi-Agent èŠ‚ç‚¹
å®šä¹‰å·¥ä½œæµä¸­çš„å„ä¸ª Agent åŠå…¶èŒè´£
"""

import logging
from typing import Dict
from modules.agent_state import AgentState, add_message, calculate_quality_score
from modules.data_fetcher import fetch_module_data
from modules.chart_builder import generate_module_charts
from modules.llm_writer import LLMWriter, prepare_btc_context, prepare_macro_context

logger = logging.getLogger(__name__)


# ==================== Agent èŠ‚ç‚¹ ====================

def chief_editor_node(state: AgentState) -> AgentState:
    """
    æ€»ç¼– Agent
    èŒè´£ï¼šä»»åŠ¡åˆ†é…ã€è´¨é‡æŠŠå…³ã€æœ€ç»ˆå®¡æ‰¹
    """
    logger.info("ğŸ“ Chief Editor å¼€å§‹å·¥ä½œ...")

    current_step = state.get("current_step", "")

    if current_step == "initialization":
        # ä»»åŠ¡åˆå§‹åŒ–ï¼šåˆ†é…ä»»åŠ¡ç»™æ•°æ®å·¥ç¨‹å¸ˆ
        state["current_step"] = "data_collection"
        state["messages"].append({
            "from_agent": "chief_editor",
            "to_agent": "data_engineer",
            "message_type": "request",
            "content": f"è¯·è·å– {state['report_period']} çš„æ‰€æœ‰æ•°æ®",
            "timestamp": "",
            "metadata": {}
        })
        logger.info("âœ… ä»»åŠ¡å·²åˆ†é…ç»™ Data Engineer")

    elif current_step == "review":
        # å®¡æ ¸æ–‡æ¡ˆè´¨é‡
        quality_score = calculate_quality_score(state)
        state["quality_score"] = quality_score

        if quality_score >= 80:
            state["approval_status"] = "approved"
            state["consensus_reached"] = True
            state["final_content"] = state.get("reviewed_content", {})
            logger.info(f"âœ… æ–‡æ¡ˆå·²é€šè¿‡å®¡æ ¸ï¼Œè´¨é‡è¯„åˆ†: {quality_score:.1f}")
        else:
            state["approval_status"] = "rejected"
            state["issues"].append(f"è´¨é‡è¯„åˆ†ä¸è¶³: {quality_score:.1f}/100")
            state["debate_rounds"] = state.get("debate_rounds", 0) + 1
            logger.warning(f"âš ï¸ æ–‡æ¡ˆéœ€è¦æ”¹è¿›ï¼Œè´¨é‡è¯„åˆ†: {quality_score:.1f}")

        state["current_step"] = "finalization"

    return state


def data_engineer_node(state: AgentState) -> AgentState:
    """
    æ•°æ®å·¥ç¨‹å¸ˆ Agent
    èŒè´£ï¼šæ•°æ®æŠ“å–ã€æ•°æ®æ¸…æ´—ã€æ•°æ®éªŒè¯
    """
    logger.info("ğŸ“Š Data Engineer å¼€å§‹å·¥ä½œ...")

    try:
        # è·å–æ‰€æœ‰æ¨¡å—æ•°æ®
        modules = ["macro"]  # åªæŠ“å–ä¸éœ€è¦ API key çš„æ¨¡å—

        raw_data = {}
        for module in modules:
            logger.info(f"æ­£åœ¨è·å– {module} æ¨¡å—æ•°æ®...")
            data = fetch_module_data(module, {})
            raw_data[module] = data

        state["raw_data"] = raw_data
        state["current_step"] = "chart_generation"

        logger.info(f"âœ… æ•°æ®è·å–å®Œæˆï¼Œå…± {len(raw_data)} ä¸ªæ¨¡å—")

    except Exception as e:
        error_msg = f"æ•°æ®è·å–å¤±è´¥: {str(e)}"
        state["errors"].append(error_msg)
        state["issues"].append(error_msg)
        logger.error(f"âŒ {error_msg}")

    return state


def chartist_node(state: AgentState) -> AgentState:
    """
    å›¾è¡¨å¸ˆ Agent
    èŒè´£ï¼šå›¾è¡¨ç”Ÿæˆã€å›¾è¡¨ä¼˜åŒ–ã€è§†è§‰å‘ˆç°
    """
    logger.info("ğŸ“ˆ Chartist å¼€å§‹å·¥ä½œ...")

    try:
        raw_data = state.get("raw_data", {})
        chart_paths = {}

        for module, data in raw_data.items():
            logger.info(f"æ­£åœ¨ç”Ÿæˆ {module} æ¨¡å—å›¾è¡¨...")
            charts = generate_module_charts(module, data)
            chart_paths[module] = charts
            logger.info(f"âœ… {module} ç”Ÿæˆäº† {len(charts)} å¼ å›¾è¡¨")

        state["chart_paths"] = chart_paths
        state["current_step"] = "content_generation"

    except Exception as e:
        error_msg = f"å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}"
        state["errors"].append(error_msg)
        state["issues"].append(error_msg)
        logger.error(f"âŒ {error_msg}")

    return state


def senior_analyst_node(state: AgentState) -> AgentState:
    """
    èµ„æ·±åˆ†æå¸ˆ Agent
    èŒè´£ï¼šLLM æ–‡æ¡ˆç”Ÿæˆã€æ•°æ®è§£è¯»ã€ä¸“ä¸šåˆ†æ
    """
    logger.info("âœï¸ Senior Analyst å¼€å§‹å·¥ä½œ...")

    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ LLM API keyï¼ˆä¼˜å…ˆä½¿ç”¨ Geminiï¼‰
        import os
        has_gemini = os.getenv("GEMINI_API_KEY") is not None
        has_openai = os.getenv("OPENAI_API_KEY") is not None

        if not (has_openai or has_gemini):
            logger.warning("âš ï¸ æœªé…ç½® LLM API Keyï¼Œä½¿ç”¨ Mock æ–‡æ¡ˆ")
            state["draft_content"] = {
                "macro_analysis": "å®è§‚åˆ†ææ–‡æ¡ˆï¼ˆMockï¼‰- è¯·é…ç½® OPENAI_API_KEY æˆ– GEMINI_API_KEY ä»¥ä½¿ç”¨çœŸå® LLM ç”Ÿæˆ"
            }
            state["reviewed_content"] = state["draft_content"]
            state["current_step"] = "review"
            return state

        # ä½¿ç”¨çœŸå® LLM ç”Ÿæˆæ–‡æ¡ˆï¼ˆä¼˜å…ˆ Gemini Flashï¼‰
        model = "gemini-flash" if has_gemini else "gpt-4o"
        writer = LLMWriter(model=model)

        # å‡†å¤‡ä¸Šä¸‹æ–‡
        raw_data = state.get("raw_data", {})
        macro_data = raw_data.get("macro", {})

        if macro_data:
            macro_context = prepare_macro_context(macro_data)
            content = writer.generate("macro_analysis", macro_context)
            state["draft_content"] = {"macro_analysis": content}
            state["reviewed_content"] = state["draft_content"]
            logger.info("âœ… LLM æ–‡æ¡ˆç”Ÿæˆå®Œæˆ")
        else:
            state["issues"].append("ç¼ºå°‘å®è§‚æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæ–‡æ¡ˆ")

        state["current_step"] = "review"

    except Exception as e:
        error_msg = f"æ–‡æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}"
        state["errors"].append(error_msg)
        state["issues"].append(error_msg)
        logger.error(f"âŒ {error_msg}")

    return state


def debate_node(state: AgentState) -> AgentState:
    """
    è¾©è®ºèŠ‚ç‚¹
    èŒè´£ï¼šAgent ä¹‹é—´çš„è´¨ç–‘ã€åé©³ã€å…±è¯†è¾¾æˆ
    """
    logger.info("ğŸ¯ Debate Node å¼€å§‹...")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦è¾©è®º
    issues = state.get("issues", [])
    debate_rounds = state.get("debate_rounds", 0)

    if len(issues) == 0:
        # æ²¡æœ‰é—®é¢˜ï¼Œç›´æ¥è¾¾æˆå…±è¯†
        state["consensus_reached"] = True
        logger.info("âœ… æ— é—®é¢˜ï¼Œè¾¾æˆå…±è¯†")
    elif debate_rounds >= 2:
        # è¶…è¿‡æœ€å¤§è½®æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
        state["consensus_reached"] = True
        logger.info("âš ï¸ è¾¾åˆ°æœ€å¤§è¾©è®ºè½®æ•°ï¼Œå¼ºåˆ¶ç»“æŸ")
    else:
        # è¿›è¡Œè¾©è®º
        logger.info(f"ğŸ”„ å¼€å§‹ç¬¬ {debate_rounds + 1} è½®è¾©è®º")

        # æ¨¡æ‹Ÿè¾©è®ºï¼šåˆ†æå¸ˆå›åº”é—®é¢˜
        state["messages"].append({
            "from_agent": "senior_analyst",
            "to_agent": "chief_editor",
            "message_type": "rebuttal",
            "content": f"å·²é’ˆå¯¹ä»¥ä¸‹é—®é¢˜è¿›è¡Œæ”¹è¿›: {', '.join(issues[:3])}",
            "timestamp": "",
            "metadata": {}
        })

        # æ¸…ç©ºé—®é¢˜åˆ—è¡¨ï¼Œå‡†å¤‡ä¸‹ä¸€è½®å®¡æ ¸
        state["issues"] = []
        state["debate_rounds"] = debate_rounds + 1
        state["current_step"] = "review"

    return state


# ==================== è·¯ç”±å‡½æ•° ====================

def route_after_chief_editor(state: AgentState) -> str:
    """å†³å®š Chief Editor ä¹‹åçš„è·¯ç”±"""
    current_step = state.get("current_step", "")

    if current_step == "data_collection":
        return "data_engineer"
    elif current_step == "finalization":
        if state.get("consensus_reached", False):
            return "end"
        else:
            return "debate"
    else:
        return "end"


def route_after_debate(state: AgentState) -> str:
    """å†³å®š Debate ä¹‹åçš„è·¯ç”±"""
    if state.get("consensus_reached", False):
        return "chief_editor"
    else:
        return "senior_analyst"  # è¿”å›è®©åˆ†æå¸ˆæ”¹è¿›


def should_continue_workflow(state: AgentState) -> bool:
    """åˆ¤æ–­å·¥ä½œæµæ˜¯å¦åº”è¯¥ç»§ç»­"""
    # å¦‚æœæœ‰ä¸¥é‡é”™è¯¯ï¼Œåœæ­¢
    if len(state.get("errors", [])) > 0:
        return False

    # å¦‚æœå·²è¾¾æˆå…±è¯†ï¼Œåœæ­¢
    if state.get("consensus_reached", False):
        return False

    # å¦‚æœè¶…è¿‡ 10 æ­¥ï¼Œå¼ºåˆ¶åœæ­¢ï¼ˆé˜²æ­¢æ­»å¾ªç¯ï¼‰
    if state.get("debate_rounds", 0) > 10:
        return False

    return True
